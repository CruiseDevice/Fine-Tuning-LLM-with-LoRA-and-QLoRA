{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cd0b5d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: peft in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (0.11.2.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from peft) (2.3.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from peft) (4.43.0.dev0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from peft) (0.31.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from huggingface-hub>=0.18.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.6.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from torch>=1.13.0->peft) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.13.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\envs\\torch\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, \\\n",
    "    TrainingArguments, Trainer, default_data_collator\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "\n",
    "# Set padding token ID in the model config\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "daf7552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Model device: \", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('ag_news')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f1bff0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_pc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5c51ee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 10\n",
      "Test dataset size: 1\n"
     ]
    }
   ],
   "source": [
    "if local_pc:\n",
    "    train_subset = dataset['train'].select(range(10))\n",
    "    test_subset = dataset['test'].select(range(1))\n",
    "    print(f\"Train dataset size: {len(train_subset)}\")\n",
    "    print(f\"Test dataset size: {len(test_subset)}\")\n",
    "else:\n",
    "    train_subset = dataset['train']\n",
    "    test_subset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "encoded_train_subset = train_subset.map(preprocess_data, batched=True)\n",
    "encoded_test_subset = test_subset.map(preprocess_data, batched=True)\n",
    "\n",
    "encoded_train_subset = encoded_train_subset.rename_column(\"label\", \"labels\")\n",
    "encoded_test_subset = encoded_test_subset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8eef70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {'accuracy': accuracy, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8f86ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\torch\\Lib\\site-packages\\transformers\\training_args.py:1522: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_train_subset,\n",
    "    eval_dataset=encoded_test_subset,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c52b07c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899168d8f8234745953fbfc523078e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foundation Model Results: {'eval_loss': 9.180270195007324, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.255, 'eval_samples_per_second': 3.922, 'eval_steps_per_second': 3.922}\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the original model\n",
    "results = trainer.evaluate(encoded_test_subset)\n",
    "print(f\"Foundation Model Results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2854b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType, AutoPeftModelForSequenceClassification, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f4619a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<TaskType.SEQ_CLS: 'SEQ_CLS'>, <TaskType.SEQ_2_SEQ_LM: 'SEQ_2_SEQ_LM'>, <TaskType.CAUSAL_LM: 'CAUSAL_LM'>, <TaskType.TOKEN_CLS: 'TOKEN_CLS'>, <TaskType.QUESTION_ANS: 'QUESTION_ANS'>, <TaskType.FEATURE_EXTRACTION: 'FEATURE_EXTRACTION'>]\n"
     ]
    }
   ],
   "source": [
    "print(list(TaskType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PEFT config\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=2,  # rank\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\torch\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:1091: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a PEFT model\n",
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning the PEFT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b202c8a89e5a471289c1926c551cd434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60edb6def0ff4cf890cb5d40c0e306ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.046016693115234, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.0621, 'eval_samples_per_second': 16.092, 'eval_steps_per_second': 16.092, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24b0acba4204be9a6186c4d027dd26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.941372871398926, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.056, 'eval_samples_per_second': 17.864, 'eval_steps_per_second': 17.864, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8126848d4e7d44659bebe488739dcbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.866525650024414, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.057, 'eval_samples_per_second': 17.547, 'eval_steps_per_second': 17.547, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ee2dfa763a4460a1f23ce6f326f1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.818970680236816, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.056, 'eval_samples_per_second': 17.857, 'eval_steps_per_second': 17.857, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94202e163c0344d9a147d47b8bf2543c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.798376083374023, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.054, 'eval_samples_per_second': 18.521, 'eval_steps_per_second': 18.521, 'epoch': 5.0}\n",
      "{'train_runtime': 33.5226, 'train_samples_per_second': 1.492, 'train_steps_per_second': 0.298, 'train_loss': 8.014313507080079, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=8.014313507080079, metrics={'train_runtime': 33.5226, 'train_samples_per_second': 1.492, 'train_steps_per_second': 0.298, 'total_flos': 13076869939200.0, 'train_loss': 8.014313507080079, 'epoch': 5.0})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the PEFT model\n",
    "print(\"Fine-tuning the PEFT model...\")\n",
    "trainer.model = peft_model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained PEFT model\n",
    "peft_model.save_pretrained('./peft_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2SdpaAttention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=2, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=2, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=4, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=4, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained PEFT model\n",
    "trained_peft_model = AutoPeftModelForSequenceClassification.from_pretrained('./peft_model', num_labels=4, pad_token_id=tokenizer.eos_token_id)\n",
    "#TODO:  use AutoPeftModelForSequenceClassification instead of PeftModel\n",
    "# trained_peft_model = PeftModel.from_pretrained(trained_peft_model, './peft_model')\n",
    "trained_peft_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the fine-tuned PEFT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48098c3c07b49b0a34cf03a825e2b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.798376083374023, 'eval_accuracy': 0.0, 'eval_f1': 0.0, 'eval_runtime': 0.1846, 'eval_samples_per_second': 5.417, 'eval_steps_per_second': 5.417, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating the fine-tuned PEFT model...\")\n",
    "trainer.model = trained_peft_model\n",
    "peft_results = trainer.evaluate()\n",
    "print(peft_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9ab80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
